{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "710c0a7d",
   "metadata": {},
   "source": [
    "# 01 — Космология: SDSS DR17 + DESI DR1 → унификация → подвыборки N=10³ и N=10⁴ → kNN‑графы\n",
    "\n",
    "**Задача ВКР:** построить сопоставимые графовые представления для двух физических доменов (космология и квантовые модели), чтобы сравнивать их **геометрию/спектры/топологию** единым пайплайном.\n",
    "\n",
    "В этом ноутбуке мы делаем космологическую часть **строго под требования квантовых выборок**:  \n",
    "- формируем подвыборки **ровно** размеров **N=1 000** и **N=10 000**;\n",
    "- строим kNN‑графы (узлы — объекты каталога, рёбра — ближайшие соседи в 3D‑координатах);\n",
    "- сохраняем результат в унифицированном формате `GraphData` (таблица узлов + таблица рёбер + метаданные), чтобы во втором ноутбуке **тот же код** работал и для квантовых семейств.\n",
    "\n",
    "**Артефакты:**  \n",
    "- нормализованные данные: `data/processed/cosmology/<preset>/...parquet`  \n",
    "- графы: `outputs/graphs/cosmology/<preset>/<source>/N_<N>/...`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf5d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Imports + reproducibility\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scientific_api.logging import setup_logging, get_logger\n",
    "from scientific_api.settings import DEFAULT_SEED, COSMO_SAMPLE_SIZES\n",
    "from scientific_api.storage.paths import ensure_all_dirs, get_repo_root, get_outputs_dir\n",
    "from scientific_api.pipeline.cosmology_ingest import run as run_cosmology_ingest\n",
    "from scientific_api.graphs.knn import GraphData, build_knn_edges, save_graphdata\n",
    "\n",
    "setup_logging(\"INFO\")\n",
    "logger = get_logger(\"nb01\")\n",
    "\n",
    "ensure_all_dirs()\n",
    "ROOT = get_repo_root()\n",
    "OUT = get_outputs_dir()\n",
    "\n",
    "print(\"Repo root:\", ROOT)\n",
    "print(\"Outputs:\", OUT)\n",
    "print(\"Sample sizes:\", COSMO_SAMPLE_SIZES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bfeefd",
   "metadata": {},
   "source": [
    "## 1) Запуск ingestion (SDSS DR17 + DESI DR1) по пресетам\n",
    "\n",
    "Пайплайн делает:\n",
    "1. загрузку/выгрузку SDSS (через запросы) в CSV;\n",
    "2. загрузку DESI DR1 LSS clustering FITS;\n",
    "3. приведение колонок к единой схеме + фильтры по пресету;\n",
    "4. сохранение в Parquet;\n",
    "5. выравнивание размеров выборок (matched downsample), чтобы SDSS и DESI сравнивались честно.\n",
    "\n",
    "**Важно:** имена столбцов исходных таблиц могут отличаться; маппинг колонок для DESI сохраняется в `outputs/ingestion/<preset>/desi_column_mapping.json`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a371289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Ingest both presets used in Chapter 1 logic\n",
    "# We run both low_z and high_z to obtain more diverse cosmology corpora.\n",
    "\n",
    "PRESETS = [\"low_z\", \"high_z\"]\n",
    "ingest_meta = {}\n",
    "\n",
    "for preset in PRESETS:\n",
    "    logger.info(f\"Running ingestion for preset={preset}\")\n",
    "    meta = run_cosmology_ingest(preset)\n",
    "    ingest_meta[preset] = meta\n",
    "    print(meta[\"summary\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f17621",
   "metadata": {},
   "source": [
    "## 2) Загрузка нормализованных matched‑выборок и проверка схемы\n",
    "\n",
    "Единая схема (см. `scientific_api.data_processing.cosmology.schema`):\n",
    "`source, sample, obj_id, ra_deg, dec_deg, z, x_mpc, y_mpc, z_mpc, weight`.\n",
    "\n",
    "Мы **не предполагаем**, что сырой SDSS/DESI имеют эти имена — мы проверяем **после нормализации**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b68fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scientific_api.data_processing.cosmology.schema import REQUIRED_COLUMNS\n",
    "\n",
    "def load_matched_points(preset: str, source: str) -> pd.DataFrame:\n",
    "    path = ROOT / \"data\" / \"processed\" / \"cosmology\" / preset / f\"{source}__matched.parquet\"\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing matched parquet: {path}\")\n",
    "    df = pd.read_parquet(path).reset_index(drop=True)\n",
    "    missing = [c for c in REQUIRED_COLUMNS if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{path} missing required columns: {missing}\")\n",
    "    return df\n",
    "\n",
    "cosmo = {}\n",
    "for preset in PRESETS:\n",
    "    cosmo[(preset, \"sdss_dr17\")] = load_matched_points(preset, \"sdss_dr17\")\n",
    "    cosmo[(preset, \"desi_dr1\")] = load_matched_points(preset, \"desi_dr1\")\n",
    "\n",
    "for (preset, source), df in cosmo.items():\n",
    "    print(f\"{preset:6s} {source:9s}  n={len(df):7d}  z-range=({df['z'].min():.3f},{df['z'].max():.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93155ba5",
   "metadata": {},
   "source": [
    "## 3) Подвыборки фиксированного размера N=1 000 и N=10 000\n",
    "\n",
    "Ключевое требование для корректного сравнения: **размер графа** должен быть сопоставим между доменами.  \n",
    "Поэтому здесь мы строим 4 графа на каждый пресет:\n",
    "- SDSS: N=1k, N=10k  \n",
    "- DESI: N=1k, N=10k\n",
    "\n",
    "Подвыборки делаем **детерминированно**: фиксируем seed, сохраняем индексы в `meta`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a544edef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_sample(df: pd.DataFrame, n: int, seed: int) -> pd.DataFrame:\n",
    "    if len(df) < n:\n",
    "        raise ValueError(f\"Requested n={n}, but dataset has only {len(df)} rows.\")\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = rng.choice(len(df), size=n, replace=False)\n",
    "    sub = df.iloc[idx].copy().reset_index(drop=True)\n",
    "    sub[\"node_id\"] = np.arange(n, dtype=int)\n",
    "    sub.attrs[\"sample_indices\"] = idx.tolist()\n",
    "    return sub\n",
    "\n",
    "samples = {}  # (preset, source, N) -> df\n",
    "for preset in PRESETS:\n",
    "    for source in [\"sdss_dr17\", \"desi_dr1\"]:\n",
    "        df = cosmo[(preset, source)]\n",
    "        for N in COSMO_SAMPLE_SIZES:\n",
    "            sub = fixed_sample(df, N, seed=DEFAULT_SEED + hash((preset, source, N)) % 10_000)\n",
    "            samples[(preset, source, N)] = sub\n",
    "            print(f\"sampled {preset} {source} N={N} -> {len(sub)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af36e2ab",
   "metadata": {},
   "source": [
    "## 4) Построение kNN‑графов и сохранение в `GraphData`\n",
    "\n",
    "- Узлы: строки DataFrame (координаты `x_mpc,y_mpc,z_mpc`, физические поля, и т.д.)\n",
    "- Рёбра: `k` ближайших соседей по евклидовой метрике в 3D\n",
    "- Вес ребра: расстояние (потом можно нормировать/инвертировать при необходимости)\n",
    "\n",
    "Сохраняем:\n",
    "`outputs/graphs/cosmology/<preset>/<source>/N_<N>/{nodes.parquet, edges.parquet, meta.json}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083b115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 12  # fixed for the project (no knobs in the notebook)\n",
    "\n",
    "graph_index_rows = []\n",
    "\n",
    "for (preset, source, N), df in samples.items():\n",
    "    coords = df[[\"x_mpc\", \"y_mpc\", \"z_mpc\"]].to_numpy(dtype=float)\n",
    "    edges = build_knn_edges(coords, k=K, metric=\"euclidean\")\n",
    "\n",
    "    nodes = df.copy()\n",
    "    # ensure required node_id\n",
    "    if \"node_id\" not in nodes.columns:\n",
    "        nodes[\"node_id\"] = np.arange(len(nodes), dtype=int)\n",
    "\n",
    "    meta = {\n",
    "        \"domain\": \"cosmology\",\n",
    "        \"preset\": preset,\n",
    "        \"source\": source,\n",
    "        \"N\": int(N),\n",
    "        \"k\": int(K),\n",
    "        \"seed\": int(DEFAULT_SEED),\n",
    "        \"coord_cols\": [\"x_mpc\", \"y_mpc\", \"z_mpc\"],\n",
    "        \"sample_indices\": df.attrs.get(\"sample_indices\", None),\n",
    "    }\n",
    "\n",
    "    g = GraphData(nodes=nodes, edges=edges, meta=meta)\n",
    "\n",
    "    out_dir = OUT / \"graphs\" / \"cosmology\" / preset / source / f\"N_{N}\"\n",
    "    save_graphdata(g, out_dir)\n",
    "\n",
    "    graph_index_rows.append({\n",
    "        \"domain\": \"cosmology\",\n",
    "        \"preset\": preset,\n",
    "        \"source\": source,\n",
    "        \"N\": N,\n",
    "        \"k\": K,\n",
    "        \"path\": str(out_dir),\n",
    "        \"n_edges\": int(edges.shape[0]),\n",
    "    })\n",
    "\n",
    "graph_index = pd.DataFrame(graph_index_rows).sort_values([\"preset\",\"source\",\"N\"])\n",
    "graph_index_path = OUT / \"graphs\" / \"graph_index_cosmology.parquet\"\n",
    "graph_index.to_parquet(graph_index_path, index=False)\n",
    "\n",
    "graph_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1cba9a",
   "metadata": {},
   "source": [
    "## 5) Визуальная проверка: 3D‑облако и распределение степеней (N=1000)\n",
    "\n",
    "Мы делаем быструю sanity‑проверку:\n",
    "- точки не вырожденные;\n",
    "- kNN‑граф не пустой;\n",
    "- степень узлов имеет ожидаемый порядок (в среднем около k).\n",
    "\n",
    "Показываем по одному примеру SDSS и DESI для каждого пресета.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81d8c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scientific_api.graphs.knn import load_graphdata\n",
    "import networkx as nx\n",
    "\n",
    "def edges_to_nx(n: int, edges: pd.DataFrame) -> nx.Graph:\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(n))\n",
    "    if len(edges) > 0:\n",
    "        G.add_weighted_edges_from(edges[[\"source\",\"target\",\"weight\"]].itertuples(index=False, name=None))\n",
    "    return G\n",
    "\n",
    "for preset in PRESETS:\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    for j, source in enumerate([\"sdss_dr17\", \"desi_dr1\"]):\n",
    "        gdir = OUT / \"graphs\" / \"cosmology\" / preset / source / \"N_1000\"\n",
    "        gd = load_graphdata(gdir)\n",
    "        nodes = gd.nodes\n",
    "        edges = gd.edges\n",
    "\n",
    "        ax = fig.add_subplot(1, 2, j+1, projection=\"3d\")\n",
    "        ax.scatter(nodes[\"x_mpc\"], nodes[\"y_mpc\"], nodes[\"z_mpc\"], s=2)\n",
    "        ax.set_title(f\"{preset} | {source} | N=1000\")\n",
    "        ax.set_xlabel(\"x_mpc\"); ax.set_ylabel(\"y_mpc\"); ax.set_zlabel(\"z_mpc\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Degree hist\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    for j, source in enumerate([\"sdss_dr17\", \"desi_dr1\"]):\n",
    "        gdir = OUT / \"graphs\" / \"cosmology\" / preset / source / \"N_1000\"\n",
    "        gd = load_graphdata(gdir)\n",
    "        G = edges_to_nx(len(gd.nodes), gd.edges)\n",
    "        deg = np.array([d for _, d in G.degree()], dtype=int)\n",
    "\n",
    "        ax = fig.add_subplot(1, 2, j+1)\n",
    "        ax.hist(deg, bins=30)\n",
    "        ax.set_title(f\"Degree hist: {preset} | {source} | mean={deg.mean():.2f}\")\n",
    "        ax.set_xlabel(\"degree\"); ax.set_ylabel(\"count\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e847f8",
   "metadata": {},
   "source": [
    "## 6) Что дальше\n",
    "\n",
    "- В этом ноутбуке получены космологические графы **строго** размеров `N=1000` и `N=10000`.\n",
    "- Во втором ноутбуке мы:\n",
    "  1) генерируем **квантовые ансамбли** на тех же N и с контролируемыми параметрами (W, p);  \n",
    "  2) извлекаем единый набор признаков;  \n",
    "  3) сравниваем домены (космология vs квантовые семейства) по структурным и спектральным метрикам.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
