{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca7b3942",
   "metadata": {},
   "source": [
    "# 02 — Experiments & Results\n",
    "Цель: провести базовый прогон, ablation и sensitivity анализ на артефактах пайплайна, сохраняя результаты в `outputs/experiments` и `reports`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd76591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ROOT = Path(\"..\").resolve()\n",
    "CFG_PATH = ROOT / \"configs\" / \"research.yaml\"\n",
    "OUT_EXP = (ROOT / \"outputs\" / \"experiments\").resolve()\n",
    "OUT_EXP.mkdir(parents=True, exist_ok=True)\n",
    "REPORT_FIGS = (ROOT / \"reports\" / \"figures\").resolve()\n",
    "REPORT_FIGS.mkdir(parents=True, exist_ok=True)\n",
    "REPORT_TABLES = (ROOT / \"reports\" / \"tables\").resolve()\n",
    "REPORT_TABLES.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "GIT_HASH = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=ROOT).decode().strip()\n",
    "PY_VER = subprocess.check_output([\"python\", \"--version\"], cwd=ROOT).decode().strip()\n",
    "PIP_HEAD = (\n",
    "    subprocess.check_output([\"python\", \"-m\", \"pip\", \"freeze\"], cwd=ROOT)\n",
    "    .decode()\n",
    "    .splitlines()[:10]\n",
    ")\n",
    "print(\"git:\", GIT_HASH)\n",
    "print(\"python:\", PY_VER)\n",
    "print(\"pip head:\", PIP_HEAD)\n",
    "\n",
    "with CFG_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    CFG: Dict = yaml.safe_load(f)\n",
    "\n",
    "random.seed(CFG[\"seed\"][\"python\"])\n",
    "np.random.seed(CFG[\"seed\"][\"numpy\"])\n",
    "\n",
    "resolved_config_path = OUT_EXP / \"config_resolved.yaml\"\n",
    "with resolved_config_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(CFG, f)\n",
    "\n",
    "{\"git\": GIT_HASH, \"python\": PY_VER, \"config_saved\": str(resolved_config_path)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81fc8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_DIR = ROOT / \"outputs\" / \"pipeline\"\n",
    "clean_path = PIPELINE_DIR / \"cleaned_combined.parquet\"\n",
    "features_path = PIPELINE_DIR / \"graph_features.parquet\"\n",
    "metrics_path = PIPELINE_DIR / \"baseline_metrics.json\"\n",
    "\n",
    "if clean_path.exists():\n",
    "    base_df = pd.read_parquet(clean_path)\n",
    "else:\n",
    "    raise FileNotFoundError(\"Run notebook 01 to generate cleaned_combined.parquet\")\n",
    "\n",
    "if features_path.exists():\n",
    "    graph_features_df = pd.read_parquet(features_path)\n",
    "else:\n",
    "    graph_features_df = pd.DataFrame()\n",
    "\n",
    "if metrics_path.exists():\n",
    "    with metrics_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        baseline_metrics = json.load(f)\n",
    "else:\n",
    "    baseline_metrics = {}\n",
    "\n",
    "print(\"Loaded\", len(base_df), \"rows; features shape\", graph_features_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1517a843",
   "metadata": {},
   "source": [
    "## Research Questions\n",
    "- Насколько признаки (ra/dec/redshift/mag) разделяют космологию и квантовую решетку?\n",
    "- Чувствительность к выбору k в kNN и числу eigenvalues.\n",
    "- Что происходит при отключении спектральной компоненты или embeddings (абляции из config)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f599c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_experiments(cfg: Dict) -> List[Dict]:\n",
    "    runs: List[Dict] = []\n",
    "    runs.append({\"name\": \"baseline\", \"features\": cfg[\"features\"], \"graph\": cfg[\"cosmology\"][\"graph\"]})\n",
    "    for abl in cfg.get(\"experiments\", {}).get(\"ablations\", []):\n",
    "        merged = {**cfg[\"features\"], **abl.get(\"features\", {})}\n",
    "        runs.append({\"name\": f\"ablation_{abl['name']}\", \"features\": merged, \"graph\": cfg[\"cosmology\"][\"graph\"]})\n",
    "    for k in cfg.get(\"experiments\", {}).get(\"sensitivity\", {}).get(\"k_neighbors\", []):\n",
    "        runs.append({\"name\": f\"sensitivity_k_{k}\", \"features\": cfg[\"features\"], \"graph\": {**cfg[\"cosmology\"][\"graph\"], \"k_neighbors\": k}})\n",
    "    for k in cfg.get(\"experiments\", {}).get(\"sensitivity\", {}).get(\"spectral_k\", []):\n",
    "        runs.append({\"name\": f\"sensitivity_eigs_{k}\", \"features\": {**cfg[\"features\"], \"spectral_k\": k}, \"graph\": cfg[\"cosmology\"][\"graph\"]})\n",
    "    return runs\n",
    "\n",
    "\n",
    "experiments_plan = expand_experiments(CFG)\n",
    "pd.DataFrame(experiments_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a3c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_COLUMNS = [\"ra\", \"dec\", \"redshift\", \"mag_g\", \"mag_r\"]\n",
    "\n",
    "\n",
    "def prepare_matrix(df: pd.DataFrame, use_spectral: bool) -> pd.DataFrame:\n",
    "    cols = BASE_COLUMNS.copy()\n",
    "    if use_spectral and not graph_features_df.empty:\n",
    "        spectral_cols = [c for c in graph_features_df.columns if c.startswith(\"eig_\")]\n",
    "        if spectral_cols:\n",
    "            spectral_row = graph_features_df.iloc[0].to_dict()\n",
    "            for col in spectral_cols:\n",
    "                df[col] = spectral_row[col]\n",
    "            cols += spectral_cols\n",
    "    return df[cols]\n",
    "\n",
    "\n",
    "def run_logreg(df: pd.DataFrame, use_spectral: bool, test_size: float) -> Dict[str, float]:\n",
    "    X = prepare_matrix(df.copy(), use_spectral)\n",
    "    y = (df[\"system_type\"] == \"cosmology\").astype(int)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=test_size, random_state=CFG[\"models\"][\"classification\"][\"random_state\"], stratify=y\n",
    "    )\n",
    "    model = LogisticRegression(max_iter=200)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return {\"accuracy\": acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0245386",
   "metadata": {},
   "outputs": [],
   "source": [
    "results: List[Dict] = []\n",
    "for run in experiments_plan:\n",
    "    use_spectral = run[\"features\"].get(\"include_spectral\", True)\n",
    "    metrics = run_logreg(base_df, use_spectral=use_spectral, test_size=CFG[\"models\"][\"classification\"][\"test_size\"])\n",
    "    results.append({\"run\": run[\"name\"], \"accuracy\": metrics[\"accuracy\"], \"use_spectral\": use_spectral, \"k_neighbors\": run[\"graph\"].get(\"k_neighbors\")})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_path = REPORT_TABLES / \"results.csv\"\n",
    "results_df.to_csv(results_path, index=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a24759",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_k = results_df[results_df[\"run\"].str.contains(\"sensitivity_k\")]\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "ax.plot(sensitivity_k[\"k_neighbors\"], sensitivity_k[\"accuracy\"], marker=\"o\")\n",
    "ax.set_xlabel(\"k neighbors\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Sensitivity to k\")\n",
    "fig.tight_layout()\n",
    "sensitivity_fig = REPORT_FIGS / \"sensitivity_k.png\"\n",
    "fig.savefig(sensitivity_fig, dpi=200)\n",
    "plt.close(fig)\n",
    "sensitivity_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd74730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_domain_distance(df: pd.DataFrame) -> float:\n",
    "    cosmo = df[df[\"system_type\"] == \"cosmology\"][BASE_COLUMNS].mean().to_numpy()\n",
    "    quantum = df[df[\"system_type\"] == \"quantum\"][BASE_COLUMNS].mean().to_numpy()\n",
    "    return float(np.linalg.norm(cosmo - quantum))\n",
    "\n",
    "\n",
    "distance_score = cross_domain_distance(base_df)\n",
    "print(\"Cross-domain mean feature distance\", distance_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700aa243",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled = base_df.copy()\n",
    "shuffled[\"system_type\"] = np.random.permutation(shuffled[\"system_type\"].values)\n",
    "sanity_metrics = run_logreg(shuffled, use_spectral=True, test_size=CFG[\"models\"][\"classification\"][\"test_size\"])\n",
    "print(\"Sanity (shuffled labels) accuracy\", sanity_metrics[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afaebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    \"git\": GIT_HASH,\n",
    "    \"baseline_accuracy\": float(results_df[results_df[\"run\"] == \"baseline\"][\"accuracy\"].iloc[0]),\n",
    "    \"best_run\": results_df.sort_values(\"accuracy\", ascending=False).iloc[0].to_dict(),\n",
    "    \"sensitivity_fig\": str(sensitivity_fig),\n",
    "    \"cross_domain_distance\": distance_score,\n",
    "    \"sanity_accuracy\": sanity_metrics[\"accuracy\"],\n",
    "    \"results_table\": str(results_path),\n",
    "}\n",
    "summary_path = REPORT_TABLES / \"summary.json\"\n",
    "with summary_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "summary_md = REPORT_TABLES / \"summary.md\"\n",
    "with summary_md.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# Experiments Summary\\n\")\n",
    "    f.write(f\"Git: {GIT_HASH}\\n\")\n",
    "    f.write(f\"Baseline accuracy: {summary['baseline_accuracy']:.3f}\\n\")\n",
    "    f.write(f\"Best run: {summary['best_run']}\\n\")\n",
    "    f.write(f\"Cross-domain distance: {distance_score:.3f}\\n\")\n",
    "    f.write(f\"Sanity (shuffled) accuracy: {sanity_metrics['accuracy']:.3f}\\n\")\n",
    "    f.write(f\"Sensitivity figure: {sensitivity_fig}\\n\")\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86879cdb",
   "metadata": {},
   "source": [
    "## Эксперименты завершены\n",
    "- Таблица результатов: `reports/tables/results.csv`\n",
    "- График чувствительности: `reports/figures/sensitivity_k.png`\n",
    "- Сводка: `reports/tables/summary.json` и `reports/tables/summary.md`\n",
    "- Исходные артефакты пайплайна: `outputs/pipeline/*`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
