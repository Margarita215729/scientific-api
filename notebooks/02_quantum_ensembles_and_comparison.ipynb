{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5255a58",
   "metadata": {},
   "source": [
    "# 02 — Квантовые ансамбли (ring / torus / RRG / rewired) → признаки → сравнение с космологией\n",
    "\n",
    "**Цель:** выполнить сравнение графовой геометрии космологических графов с контролируемыми квантовыми семействами, строго соблюдая критерии:\n",
    "\n",
    "- топологии: регулярные (1D ring, 2D torus), нерегулярные (RRG), и «решётка с нарушениями» (rewired torus);\n",
    "- размеры: **N=1 000** и **N=10 000** (как в космологии);\n",
    "- управляемые параметры беспорядка: onsite‑disorder **W** и структурный шум **p**;\n",
    "- ансамбли: **50 реализаций на точку параметров**;\n",
    "- единый формат: таблицы `nodes/edges` + метаданные, без специальных ветвлений в коде.\n",
    "\n",
    "Мы сравниваем:\n",
    "1) топологические признаки (степени, кластеризация, компоненты, плотность);  \n",
    "2) спектральные признаки (низшие собственные значения нормализованного лапласиана);  \n",
    "3) квантовые маркеры локализации (частичный спектр гамильтониана + IPR на выбранных собственных векторах).\n",
    "\n",
    "> Этот ноутбук предполагает, что `01_cosmology_ingest_and_graph.ipynb` уже выполнен и артефакты лежат в `outputs/graphs/...`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Imports + paths\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scientific_api.logging import setup_logging, get_logger\n",
    "from scientific_api.settings import DEFAULT_SEED, COSMO_SAMPLE_SIZES, ENSEMBLE_SIZE\n",
    "from scientific_api.storage.paths import get_repo_root, get_outputs_dir, get_reports_dir, ensure_all_dirs\n",
    "from scientific_api.graphs.knn import load_graphdata\n",
    "from scientific_api.features.graph_features import featurize_graph\n",
    "from scientific_api.quantum.ensembles import quantum_graph_ensemble\n",
    "\n",
    "setup_logging(\"INFO\")\n",
    "logger = get_logger(\"nb02\")\n",
    "\n",
    "ensure_all_dirs()\n",
    "ROOT = get_repo_root()\n",
    "OUT = get_outputs_dir()\n",
    "REP = get_reports_dir()\n",
    "\n",
    "print(\"Repo:\", ROOT)\n",
    "print(\"Outputs:\", OUT)\n",
    "print(\"Reports:\", REP)\n",
    "print(\"Ensemble size:\", ENSEMBLE_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5cbb8c",
   "metadata": {},
   "source": [
    "## 1) Загрузка космологических графов и вычисление признаков\n",
    "\n",
    "Мы работаем отдельно для N=1000 и N=10000, чтобы не смешивать «масштаб» графа как фактор.\n",
    "\n",
    "Признаки считаются функцией `featurize_graph(nodes, edges)`:\n",
    "- топология + спектр лапласиана (низшие eigenvalues).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1940ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo_index_path = OUT / \"graphs\" / \"graph_index_cosmology.parquet\"\n",
    "if not cosmo_index_path.exists():\n",
    "    raise FileNotFoundError(f\"Cosmology graph index missing: {cosmo_index_path}. Run notebook 01 first.\")\n",
    "\n",
    "cosmo_index = pd.read_parquet(cosmo_index_path)\n",
    "cosmo_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e588fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_cosmology_row(row: pd.Series, spectral_k: int = 32) -> dict:\n",
    "    gd = load_graphdata(Path(row[\"path\"]))\n",
    "    feats = featurize_graph(gd.nodes, gd.edges, spectral_k=spectral_k)\n",
    "    feats |= {\n",
    "        \"domain\": \"cosmology\",\n",
    "        \"preset\": row[\"preset\"],\n",
    "        \"source\": row[\"source\"],\n",
    "        \"N\": int(row[\"N\"]),\n",
    "        \"graph_id\": f\"{row['preset']}__{row['source']}__N{row['N']}\",\n",
    "    }\n",
    "    return feats\n",
    "\n",
    "cosmo_features = pd.DataFrame([featurize_cosmology_row(r) for _, r in cosmo_index.iterrows()])\n",
    "cosmo_features.sort_values([\"N\",\"preset\",\"source\"]).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6090f05",
   "metadata": {},
   "source": [
    "## 2) Дизайн квантовых экспериментов (фиксируем без «опционально»)\n",
    "\n",
    "Мы сканируем параметр onsite‑disorder **W** и структурный шум **p**:\n",
    "\n",
    "- `ring`, `torus`, `rrg`: **W ∈ {0.0, 2.0, 6.0}**, p=0  \n",
    "- `rewired_torus`: **W = 2.0**, **p ∈ {0.00, 0.05, 0.15}**\n",
    "\n",
    "Размеры:\n",
    "- **N=1 000**: ring/rrg + torus/rewired (torus требует N=perfect square → 1000 не квадрат).  \n",
    "- **N=10 000**: ring, torus (100×100), rrg, rewired_torus.\n",
    "\n",
    "Чтобы соблюсти критерий сопоставимости размеров, для N=1000 мы используем:\n",
    "- ring (N=1000),\n",
    "- rrg (N=1000),\n",
    "- вместо torus используем **ближайший квадрат** 32×32=1024 и затем *строго* приводим к N=1000, удаляя 24 узла детерминированно.\n",
    "Это сохраняет «2D‑решётку как эталон упорядоченности» и одновременно выполняет требование N.\n",
    "\n",
    "Детерминированность: seed фиксируем и записываем в таблицу результатов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8d3ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2A) Utilities: enforce exact N for lattice-based families when n is not a perfect square.\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "def enforce_exact_n(nodes: pd.DataFrame, edges: pd.DataFrame, n_target: int, seed: int):\n",
    "    \"\"\"Drop nodes deterministically to reach exact n_target.\n",
    "\n",
    "    Returns:\n",
    "      nodes2, edges2, keep_old_ids, mapping_old_to_new\n",
    "    \"\"\"\n",
    "    n0 = len(nodes)\n",
    "    if n0 == n_target:\n",
    "        keep_old = nodes[\"node_id\"].to_numpy(int)\n",
    "        mapping = {int(old): int(old) for old in keep_old}\n",
    "        return nodes.copy(), edges.copy(), keep_old, mapping\n",
    "\n",
    "    if n0 < n_target:\n",
    "        raise ValueError(f\"Cannot enlarge graph: have {n0} nodes, need {n_target}\")\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    drop = rng.choice(n0, size=(n0 - n_target), replace=False)\n",
    "    keep_mask = np.ones(n0, dtype=bool)\n",
    "    keep_mask[drop] = False\n",
    "\n",
    "    old_ids = nodes[\"node_id\"].to_numpy(int)\n",
    "    keep_old = old_ids[keep_mask]\n",
    "    mapping = {int(old): int(i) for i, old in enumerate(keep_old)}\n",
    "\n",
    "    nodes2 = nodes.loc[keep_mask].copy().reset_index(drop=True)\n",
    "    nodes2[\"node_id\"] = np.arange(len(nodes2), dtype=int)\n",
    "\n",
    "    e = edges.copy()\n",
    "    e = e[e[\"source\"].isin(mapping) & e[\"target\"].isin(mapping)].copy()\n",
    "    e[\"source\"] = e[\"source\"].map(mapping).astype(int)\n",
    "    e[\"target\"] = e[\"target\"].map(mapping).astype(int)\n",
    "    e = e[e[\"source\"] != e[\"target\"]].copy()\n",
    "\n",
    "    return nodes2, e.reset_index(drop=True), keep_old, mapping\n",
    "\n",
    "# sanity check: applied later in generation step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc92e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2B) Define design grid in an explicit table.\n",
    "\n",
    "design_rows = []\n",
    "\n",
    "W_grid = [0.0, 2.0, 6.0]\n",
    "p_grid_rewired = [0.00, 0.05, 0.15]\n",
    "\n",
    "for N in COSMO_SAMPLE_SIZES:\n",
    "    # ring\n",
    "    for W in W_grid:\n",
    "        design_rows.append({\"family\":\"ring\", \"N\":N, \"W\":W, \"p\":0.0})\n",
    "    # rrg\n",
    "    for W in W_grid:\n",
    "        design_rows.append({\"family\":\"rrg\", \"N\":N, \"W\":W, \"p\":0.0})\n",
    "    # torus only if perfect square or handled by enforce_exact_n\n",
    "    for W in W_grid:\n",
    "        design_rows.append({\"family\":\"torus\", \"N\":N, \"W\":W, \"p\":0.0})\n",
    "    # rewired torus\n",
    "    for p in p_grid_rewired:\n",
    "        design_rows.append({\"family\":\"rewired_torus\", \"N\":N, \"W\":2.0, \"p\":p})\n",
    "\n",
    "design = pd.DataFrame(design_rows)\n",
    "design\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9da763",
   "metadata": {},
   "source": [
    "## 3) Генерация ансамблей и вычисление признаков\n",
    "\n",
    "Для каждой точки дизайна мы генерируем **50 реализаций** и считаем:\n",
    "- те же графовые признаки, что и для космологии (`featurize_graph`);\n",
    "- дополнительно: частичный спектр гамильтониана и IPR (квантовый маркер локализации).\n",
    "\n",
    "Для N=10 000 мы **не** считаем полный спектр (слишком дорого), а используем `eigsh` на малом числе собственных значений/векторов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76940446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "def quantum_extra_metrics(member: dict, k_h: int = 8) -> dict:\n",
    "    H = member[\"H\"]\n",
    "    n = H.shape[0]\n",
    "    k_eff = min(k_h, n-2) if n > 2 else 0\n",
    "    if k_eff <= 0:\n",
    "        return {\"H_eig_mean\": np.nan, \"H_eig_std\": np.nan, \"IPR_mean\": np.nan, \"IPR_std\": np.nan}\n",
    "\n",
    "    # symmetric Hamiltonian; take eigenpairs near smallest algebraic values as a stable proxy\n",
    "    try:\n",
    "        vals, vecs = eigsh(H, k=k_eff, which=\"SA\")\n",
    "        vals = np.real(vals)\n",
    "        # IPR on eigenvectors (columns)\n",
    "        psi2 = np.abs(vecs)**2\n",
    "        psi2 = psi2 / np.sum(psi2, axis=0, keepdims=True)\n",
    "        ipr = np.sum(psi2**2, axis=0)\n",
    "        return {\n",
    "            \"H_eig_mean\": float(np.mean(vals)),\n",
    "            \"H_eig_std\": float(np.std(vals)),\n",
    "            \"IPR_mean\": float(np.mean(ipr)),\n",
    "            \"IPR_std\": float(np.std(ipr)),\n",
    "        }\n",
    "    except Exception:\n",
    "        return {\"H_eig_mean\": np.nan, \"H_eig_std\": np.nan, \"IPR_mean\": np.nan, \"IPR_std\": np.nan}\n",
    "\n",
    "def featurize_quantum_member(member: dict, spectral_k: int = 32) -> dict:\n",
    "    nodes = member[\"nodes\"]\n",
    "    edges = member[\"edges\"]\n",
    "    feats = featurize_graph(nodes, edges, spectral_k=spectral_k)\n",
    "    feats |= quantum_extra_metrics(member, k_h=8)\n",
    "    feats |= {\n",
    "        \"domain\": \"quantum\",\n",
    "        \"family\": member[\"family\"],\n",
    "        \"N\": int(member[\"n\"]),\n",
    "        \"W\": float(member[\"W\"]),\n",
    "        \"p\": float(member[\"p\"]),\n",
    "        \"seed\": int(member[\"seed\"]),\n",
    "    }\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c05c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantum_features_rows = []\n",
    "\n",
    "for _, drow in design.iterrows():\n",
    "    family = drow[\"family\"]\n",
    "    N_target = int(drow[\"N\"])\n",
    "    W = float(drow[\"W\"])\n",
    "    p = float(drow[\"p\"])\n",
    "\n",
    "    # For torus-based families, build on the nearest square if needed\n",
    "    if family in (\"torus\", \"rewired_torus\"):\n",
    "        side = int(np.round(np.sqrt(N_target)))\n",
    "        n_square = side * side\n",
    "        N_generate = n_square if n_square != N_target else N_target\n",
    "    else:\n",
    "        N_generate = N_target\n",
    "\n",
    "    seed = DEFAULT_SEED + (hash((family, N_target, W, p)) % 1_000_000)\n",
    "    logger.info(f\"Quantum: {family} N={N_target} (gen={N_generate}) W={W} p={p} seed={seed}\")\n",
    "\n",
    "    members = quantum_graph_ensemble(\n",
    "        family=family,\n",
    "        n=N_generate,\n",
    "        W=W,\n",
    "        p=p,\n",
    "        ensemble_size=ENSEMBLE_SIZE,\n",
    "        seed=seed,\n",
    "        rrg_degree=4,\n",
    "    )\n",
    "\n",
    "    for m in members:\n",
    "        # enforce exact N for torus-based if needed\n",
    "        if N_generate != N_target:\n",
    "            nodes2, edges2, keep_old_ids, mapping = enforce_exact_n(\n",
    "                m[\"nodes\"], m[\"edges\"], n_target=N_target, seed=m[\"seed\"]\n",
    "            )\n",
    "\n",
    "            # reduce onsite potentials consistently with kept nodes\n",
    "            eps_full = np.asarray(m[\"onsite\"], dtype=float)\n",
    "            eps_keep = eps_full[keep_old_ids]\n",
    "\n",
    "            # reduce Hamiltonian consistently by submatrix selection\n",
    "            H_full = m[\"H\"].tocsr()\n",
    "            H_red = H_full[keep_old_ids, :][:, keep_old_ids]\n",
    "\n",
    "            m = dict(m)\n",
    "            m[\"nodes\"] = nodes2\n",
    "            m[\"edges\"] = edges2\n",
    "            m[\"onsite\"] = eps_keep\n",
    "            m[\"H\"] = H_red\n",
    "            m[\"n\"] = N_target\n",
    "\n",
    "        quantum_features_rows.append(featurize_quantum_member(m, spectral_k=32))\n",
    "\n",
    "quantum_features = pd.DataFrame(quantum_features_rows)\n",
    "quantum_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e35c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw (per-realization) quantum features for full reproducibility\n",
    "REP.mkdir(parents=True, exist_ok=True)\n",
    "quantum_features_path = REP / \"tables\" / \"quantum_features_per_realization.parquet\"\n",
    "quantum_features_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "quantum_features.to_parquet(quantum_features_path, index=False)\n",
    "quantum_features_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e03ca",
   "metadata": {},
   "source": [
    "## 4) Агрегация по ансамблям: средние и дисперсии\n",
    "\n",
    "Для сравнения с космологией мы используем:\n",
    "- космология: отдельные графы (4 графа на пресет, 2 источника, 2 N)\n",
    "- квантовые: усреднение по 50 реализациям на точку (W,p,family,N)\n",
    "\n",
    "Это соответствует критерию «не одна реализация, а ансамбль».\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d5b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = [\"family\",\"N\",\"W\",\"p\"]\n",
    "\n",
    "# numeric columns only\n",
    "num_cols = [c for c in quantum_features.columns if pd.api.types.is_numeric_dtype(quantum_features[c]) and c not in [\"seed\"]]\n",
    "\n",
    "quantum_agg = (quantum_features\n",
    "              .groupby(group_cols)[num_cols]\n",
    "              .agg([\"mean\",\"std\"])\n",
    "              )\n",
    "\n",
    "# flatten columns\n",
    "quantum_agg.columns = [f\"{c}__{stat}\" for c, stat in quantum_agg.columns]\n",
    "quantum_agg = quantum_agg.reset_index()\n",
    "\n",
    "quantum_agg_path = REP / \"tables\" / \"quantum_features_aggregated.parquet\"\n",
    "quantum_agg.to_parquet(quantum_agg_path, index=False)\n",
    "\n",
    "quantum_agg.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116b2507",
   "metadata": {},
   "source": [
    "## 5) Сравнение доменов в едином признаковом пространстве\n",
    "\n",
    "Мы сравниваем на каждом N отдельно:\n",
    "\n",
    "1) стандартизируем признаки на объединённом наборе (космология + квантовые средние);\n",
    "2) считаем расстояния от каждого космологического графа до каждой квантовой точки (семейство/параметры);\n",
    "3) визуализируем (теплокарта) и делаем простую интерпретацию: какая квантовая «геометрия» ближе к SDSS/DESI.\n",
    "\n",
    "Метрика: Евклидово расстояние в z‑нормированном пространстве признаков.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1678d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def compare_for_N(N: int):\n",
    "    cos = cosmo_features[cosmo_features[\"N\"] == N].copy()\n",
    "    q = quantum_agg[quantum_agg[\"N\"] == N].copy()\n",
    "\n",
    "    # choose a stable feature subset (avoid seed, meta)\n",
    "    # We use topology + laplacian eigs + quantum extras (means only).\n",
    "    feature_cols = [c for c in cos.columns if c.startswith((\"n_\",\"density\",\"deg_\",\"clustering\",\"assortativity\",\"n_components\",\"lap_eig_\",\"spectral_gap\"))]\n",
    "    # For quantum aggregated we have \"<feature>__mean\" columns\n",
    "    q_feature_cols = [f\"{c}__mean\" for c in feature_cols if f\"{c}__mean\" in q.columns]\n",
    "\n",
    "    # align\n",
    "    X_cos = cos[feature_cols].copy()\n",
    "    X_q = q[q_feature_cols].copy()\n",
    "    X_q.columns = feature_cols\n",
    "\n",
    "    X_all = pd.concat([X_cos, X_q], axis=0, ignore_index=True)\n",
    "    X_all = X_all.fillna(X_all.mean(numeric_only=True))\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_all_z = scaler.fit_transform(X_all.values)\n",
    "\n",
    "    X_cos_z = X_all_z[:len(X_cos)]\n",
    "    X_q_z = X_all_z[len(X_cos):]\n",
    "\n",
    "    # pairwise distances\n",
    "    dists = np.sqrt(((X_cos_z[:, None, :] - X_q_z[None, :, :])**2).sum(axis=2))\n",
    "\n",
    "    dist_df = pd.DataFrame(dists, index=cos[\"graph_id\"].tolist(), columns=[f\"{r.family}|W={r.W}|p={r.p}\" for r in q.itertuples()])\n",
    "    return cos, q, dist_df\n",
    "\n",
    "comparisons = {}\n",
    "for N in COSMO_SAMPLE_SIZES:\n",
    "    comparisons[N] = compare_for_N(int(N))\n",
    "    print(N, comparisons[N][2].shape)\n",
    "\n",
    "# show N=1000 distance table\n",
    "comparisons[1000][2].iloc[:, :10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c31d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap visualization for each N (cosmology graphs vs quantum design points)\n",
    "\n",
    "def plot_heatmap(dist_df: pd.DataFrame, title: str):\n",
    "    fig = plt.figure(figsize=(12, 3 + 0.3*len(dist_df)))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    im = ax.imshow(dist_df.values, aspect=\"auto\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_yticks(range(len(dist_df.index)))\n",
    "    ax.set_yticklabels(dist_df.index)\n",
    "    ax.set_xticks(range(len(dist_df.columns)))\n",
    "    ax.set_xticklabels(dist_df.columns, rotation=90, fontsize=7)\n",
    "    plt.colorbar(im, ax=ax, fraction=0.03, pad=0.02, label=\"z-space distance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for N in COSMO_SAMPLE_SIZES:\n",
    "    _, _, dist_df = comparisons[int(N)]\n",
    "    plot_heatmap(dist_df, title=f\"Cosmology→Quantum distances (N={N})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2221ba06",
   "metadata": {},
   "source": [
    "## 6) PCA‑проекция: совместная «карта» геометрий\n",
    "\n",
    "Показываем, как космологические графы располагаются относительно квантовых средних точек в низкоразмерном пространстве признаков.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be9ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def pca_map_for_N(N: int):\n",
    "    cos = cosmo_features[cosmo_features[\"N\"] == N].copy()\n",
    "    q = quantum_agg[quantum_agg[\"N\"] == N].copy()\n",
    "\n",
    "    feature_cols = [c for c in cos.columns if c.startswith((\"n_\",\"density\",\"deg_\",\"clustering\",\"assortativity\",\"n_components\",\"lap_eig_\",\"spectral_gap\"))]\n",
    "    q_feature_cols = [f\"{c}__mean\" for c in feature_cols if f\"{c}__mean\" in q.columns]\n",
    "\n",
    "    X_cos = cos[feature_cols].copy()\n",
    "    X_q = q[q_feature_cols].copy()\n",
    "    X_q.columns = feature_cols\n",
    "\n",
    "    X_all = pd.concat([X_cos, X_q], axis=0, ignore_index=True)\n",
    "    X_all = X_all.fillna(X_all.mean(numeric_only=True))\n",
    "\n",
    "    Xz = StandardScaler().fit_transform(X_all.values)\n",
    "    Z = PCA(n_components=2, random_state=DEFAULT_SEED).fit_transform(Xz)\n",
    "\n",
    "    Z_cos = Z[:len(X_cos)]\n",
    "    Z_q = Z[len(X_cos):]\n",
    "\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "    ax.scatter(Z_q[:,0], Z_q[:,1], marker=\"s\", s=60)\n",
    "    for i, r in enumerate(q.itertuples()):\n",
    "        ax.text(Z_q[i,0], Z_q[i,1], f\"{r.family}\\nW={r.W},p={r.p}\", fontsize=7)\n",
    "\n",
    "    ax.scatter(Z_cos[:,0], Z_cos[:,1], marker=\"o\", s=80)\n",
    "    for i, r in enumerate(cos.itertuples()):\n",
    "        ax.text(Z_cos[i,0], Z_cos[i,1], f\"{r.preset}|{r.source}\", fontsize=9)\n",
    "\n",
    "    ax.set_title(f\"PCA map of graph features (N={N})\")\n",
    "    ax.set_xlabel(\"PC1\"); ax.set_ylabel(\"PC2\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for N in COSMO_SAMPLE_SIZES:\n",
    "    pca_map_for_N(int(N))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2984a283",
   "metadata": {},
   "source": [
    "## 7) Итоговые таблицы для вставки в Главы 2–3\n",
    "\n",
    "Мы сохраняем:\n",
    "- `reports/tables/cosmology_features.parquet`\n",
    "- `reports/tables/quantum_features_aggregated.parquet`\n",
    "- `reports/tables/comparison_distances_<N>.csv`\n",
    "\n",
    "Эти таблицы можно напрямую использовать для графиков/таблиц ВКР.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a24d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo_features_path = REP / \"tables\" / \"cosmology_features.parquet\"\n",
    "cosmo_features_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "cosmo_features.to_parquet(cosmo_features_path, index=False)\n",
    "\n",
    "for N in COSMO_SAMPLE_SIZES:\n",
    "    dist_df = comparisons[int(N)][2]\n",
    "    out_csv = REP / \"tables\" / f\"comparison_distances_N{int(N)}.csv\"\n",
    "    dist_df.to_csv(out_csv)\n",
    "\n",
    "cosmo_features_path, quantum_agg_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c31337",
   "metadata": {},
   "source": [
    "## 8) Научная интерпретация (что формально проверяем)\n",
    "\n",
    "1) **Гипотеза о «близости геометрий»**: космологические графы ближе к семействам с нарушенной регулярностью (RRG / rewired torus), чем к идеально регулярным (ring/torus при W≈0).  \n",
    "2) **Роль дизордера W**: увеличение W в квантовой части должно менять спектральные и локализационные маркеры; мы проверяем, в какую сторону это сдвигает квантовые точки относительно космологии.  \n",
    "3) **Различия SDSS vs DESI**: если SDSS и DESI дают систематически разные расстояния до тех же квантовых семейств, это — наблюдаемая разница «геометрии каталогов» на фиксированном масштабе.\n",
    "\n",
    "Дальше (в тексте главы) вы берёте таблицы и иллюстрации этого ноутбука и формулируете выводы строго по числам/графикам.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
