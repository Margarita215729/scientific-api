{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aff896a1",
   "metadata": {},
   "source": [
    "# 01 — Pipeline Implementation\n",
    "Цель: инженерно воспроизвести пайплайн (данные → графы → фичи → модели → метрики), сохранять артефакты в `outputs/pipeline` и фиксировать метаданные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f11d4f",
   "metadata": {},
   "source": [
    "## Контекст и план\n",
    "- Читаем конфиг `configs/research.yaml` для путей, параметров графов и моделей.\n",
    "- Используем синтетические данные для космологии (ra/dec/z) и квантовой сетки (x/y/potential), чтобы воспроизводимо прогнать цепочку.\n",
    "- Шаги: загрузка конфигурации → установка сидов → генерация и очистка данных → построение графов → вычисление признаков → обучение базовой модели → метрики и артефакты в `outputs/pipeline` и `reports/figures`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e31c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "CONFIG_PATH = Path(\"../configs/research.yaml\").resolve()\n",
    "with CONFIG_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    CFG: Dict = yaml.safe_load(f)\n",
    "\n",
    "DATA_ROOT = Path(CFG[\"paths\"][\"data_root\"]).resolve()\n",
    "OUT_PIPELINE = Path(CFG[\"paths\"][\"outputs_pipeline\"]).resolve()\n",
    "OUT_PIPELINE.mkdir(parents=True, exist_ok=True)\n",
    "OUT_FIGS = Path(CFG[\"paths\"][\"reports_figures\"]).resolve()\n",
    "OUT_FIGS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Loaded config from\", CONFIG_PATH)\n",
    "CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621f246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed_python: int, seed_numpy: int) -> None:\n",
    "    \"\"\"Deterministic seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed_python)\n",
    "    np.random.seed(seed_numpy)\n",
    "\n",
    "\n",
    "set_seeds(CFG[\"seed\"][\"python\"], CFG[\"seed\"][\"numpy\"])\n",
    "print(\"Seeds set to\", CFG[\"seed\"][\"python\"], CFG[\"seed\"][\"numpy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be1ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cosmology_sample(n: int) -> pd.DataFrame:\n",
    "    \"\"\"Synthetic RA/Dec/redshift sample within configured ranges.\"\"\"\n",
    "    ra_min, ra_max = CFG[\"cosmology\"][\"ra_range\"]\n",
    "    dec_min, dec_max = CFG[\"cosmology\"][\"dec_range\"]\n",
    "    z_min, z_max = CFG[\"cosmology\"][\"redshift_range\"]\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"ra\": np.random.uniform(ra_min, ra_max, size=n),\n",
    "            \"dec\": np.random.uniform(dec_min, dec_max, size=n),\n",
    "            \"redshift\": np.random.uniform(z_min, z_max, size=n),\n",
    "            \"mag_g\": np.random.normal(22, 1.5, size=n),\n",
    "            \"mag_r\": np.random.normal(21, 1.2, size=n),\n",
    "        }\n",
    "    )\n",
    "    df[\"system_type\"] = \"cosmology\"\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_quantum_grid(grid: int) -> pd.DataFrame:\n",
    "    \"\"\"Synthetic quantum lattice with simple potential pattern.\"\"\"\n",
    "    coords = np.linspace(-1.0, 1.0, grid)\n",
    "    xs, ys = np.meshgrid(coords, coords)\n",
    "    potential = np.sin(np.pi * xs) * np.cos(np.pi * ys)\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"x\": xs.ravel(),\n",
    "            \"y\": ys.ravel(),\n",
    "            \"potential\": potential.ravel(),\n",
    "        }\n",
    "    )\n",
    "    df[\"system_type\"] = \"quantum\"\n",
    "    return df\n",
    "\n",
    "\n",
    "cosmo_df = generate_cosmology_sample(min(500, CFG[\"cosmology\"][\"max_galaxies\"]))\n",
    "quantum_df = generate_quantum_grid(grid=CFG[\"quantum\"][\"grid_size\"])\n",
    "print(\"Cosmology rows\", len(cosmo_df), \"Quantum rows\", len(quantum_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7afa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cosmology(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna(subset=[\"ra\", \"dec\", \"redshift\"])\n",
    "    df = df[(df[\"ra\"].between(0, 360)) & (df[\"dec\"].between(-90, 90))]\n",
    "    df = df[(df[\"redshift\"] >= 0) & (df[\"redshift\"] <= 1.0)]\n",
    "    df = df[df[\"mag_g\"].between(15, 30) & df[\"mag_r\"].between(15, 30)]\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "    df[\"x\"] = np.cos(np.radians(df[\"dec\"])) * np.cos(np.radians(df[\"ra\"]))\n",
    "    df[\"y\"] = np.cos(np.radians(df[\"dec\"])) * np.sin(np.radians(df[\"ra\"]))\n",
    "    df[\"z\"] = np.sin(np.radians(df[\"dec\"]))\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_quantum(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"ra\"] = (df[\"x\"] + 1.0) * 180  # place lattice into RA-like space\n",
    "    df[\"dec\"] = (df[\"y\"] + 1.0) * 45 - 45\n",
    "    df[\"redshift\"] = 0.05 + 0.02 * df[\"potential\"]\n",
    "    df[\"mag_g\"] = 20 + 0.5 * df[\"potential\"]\n",
    "    df[\"mag_r\"] = 19.5 + 0.4 * df[\"potential\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "cosmo_clean = clean_cosmology(cosmo_df)\n",
    "quantum_clean = clean_quantum(quantum_df)\n",
    "combined = pd.concat([cosmo_clean, quantum_clean], ignore_index=True)\n",
    "print(\"Combined rows after cleaning\", len(combined))\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fabfb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_knn_graph(df: pd.DataFrame, k: int = 10) -> nx.Graph:\n",
    "    coords = df[[\"x\", \"y\", \"z\"]].to_numpy()\n",
    "    g = nx.Graph(system_type=df[\"system_type\"].iloc[0])\n",
    "    for idx, row in df.iterrows():\n",
    "        g.add_node(idx, ra=row.ra, dec=row.dec, redshift=row.redshift)\n",
    "    # Compute pairwise distances and connect k nearest for each node\n",
    "    for i, origin in enumerate(coords):\n",
    "        dists = np.linalg.norm(coords - origin, axis=1)\n",
    "        nearest = np.argsort(dists)[1 : k + 1]\n",
    "        for j in nearest:\n",
    "            weight = float(dists[j])\n",
    "            g.add_edge(i, j, weight=weight)\n",
    "    return g\n",
    "\n",
    "\n",
    "def build_quantum_graph(df: pd.DataFrame, max_nodes: int = 1500) -> nx.Graph:\n",
    "    # Downsample grid if too large\n",
    "    df_sampled = df.sample(n=min(max_nodes, len(df)), random_state=CFG[\"seed\"][\"python\"])\n",
    "    g = nx.Graph(system_type=\"quantum\")\n",
    "    for idx, row in df_sampled.iterrows():\n",
    "        g.add_node(idx, x=row.x, y=row.y, potential=row.potential)\n",
    "    # Connect 4-neighborhood on lattice approximation\n",
    "    arr = df_sampled[[\"x\", \"y\"]].to_numpy()\n",
    "    for i, origin in enumerate(arr):\n",
    "        dists = np.linalg.norm(arr - origin, axis=1)\n",
    "        nearest = np.argsort(dists)[1:5]\n",
    "        for j in nearest:\n",
    "            g.add_edge(i, j, weight=float(dists[j]))\n",
    "    return g\n",
    "\n",
    "\n",
    "cosmo_graph = build_knn_graph(cosmo_clean, k=CFG[\"cosmology\"][\"graph\"][\"k_neighbors\"])\n",
    "quantum_graph = build_quantum_graph(quantum_clean, max_nodes=CFG[\"quantum\"][\"graph\"][\"max_nodes\"])\n",
    "print(nx.info(cosmo_graph))\n",
    "print(nx.info(quantum_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93913307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_features(g: nx.Graph, spectral_k: int = 10) -> Dict[str, float]:\n",
    "    degrees = np.array([deg for _, deg in g.degree()])\n",
    "    clustering = nx.average_clustering(g)\n",
    "    assort = nx.degree_assortativity_coefficient(g) if g.number_of_edges() > 0 else 0.0\n",
    "    lap = nx.normalized_laplacian_matrix(g).toarray()\n",
    "    eigvals = np.linalg.eigvalsh(lap)\n",
    "    eigvals_sorted = np.sort(eigvals)[:spectral_k]\n",
    "    return {\n",
    "        \"nodes\": g.number_of_nodes(),\n",
    "        \"edges\": g.number_of_edges(),\n",
    "        \"degree_mean\": float(degrees.mean()),\n",
    "        \"degree_std\": float(degrees.std()),\n",
    "        \"clustering\": float(clustering),\n",
    "        \"assortativity\": float(assort),\n",
    "        **{f\"eig_{i}\": float(v) for i, v in enumerate(eigvals_sorted)},\n",
    "    }\n",
    "\n",
    "\n",
    "cosmo_feats = graph_features(cosmo_graph, spectral_k=CFG[\"features\"][\"spectral_k\"])\n",
    "quantum_feats = graph_features(quantum_graph, spectral_k=CFG[\"features\"][\"spectral_k\"])\n",
    "features_df = pd.DataFrame([cosmo_feats, quantum_feats])\n",
    "features_df.insert(0, \"system_type\", [\"cosmology\", \"quantum\"])\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387c1a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_baseline_classifier(df: pd.DataFrame) -> Tuple[LogisticRegression, Dict[str, float]]:\n",
    "    feat_cols = [\"ra\", \"dec\", \"redshift\", \"mag_g\", \"mag_r\"]\n",
    "    X = df[feat_cols].to_numpy()\n",
    "    y = (df[\"system_type\"] == \"cosmology\").astype(int)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=CFG[\"models\"][\"classification\"][\"test_size\"], random_state=CFG[\"models\"][\"classification\"][\"random_state\"], stratify=y\n",
    "    )\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    model = LogisticRegression(max_iter=200)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    return model, {\"accuracy\": acc, \"report\": report, \"scaler\": scaler}\n",
    "\n",
    "\n",
    "baseline_model, baseline_metrics = train_baseline_classifier(combined)\n",
    "print(\"Baseline accuracy\", baseline_metrics[\"accuracy\"])\n",
    "list(baseline_metrics[\"report\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb3db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_projection(df: pd.DataFrame, path: Path) -> Path:\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    for name, group in df.groupby(\"system_type\"):\n",
    "        ax.scatter(group[\"ra\"], group[\"dec\"], s=10, alpha=0.6, label=name)\n",
    "    ax.set_xlabel(\"RA\")\n",
    "    ax.set_ylabel(\"Dec\")\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path, dpi=200)\n",
    "    plt.close(fig)\n",
    "    return path\n",
    "\n",
    "\n",
    "def plot_degree_hist(g: nx.Graph, path: Path) -> Path:\n",
    "    degrees = [d for _, d in g.degree()]\n",
    "    fig, ax = plt.subplots(figsize=(5, 3))\n",
    "    ax.hist(degrees, bins=20)\n",
    "    ax.set_title(f\"Degree distribution: {g.graph.get('system_type', 'graph')}\")\n",
    "    ax.set_xlabel(\"Degree\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path, dpi=200)\n",
    "    plt.close(fig)\n",
    "    return path\n",
    "\n",
    "\n",
    "proj_path = OUT_FIGS / \"pipeline_projection.png\"\n",
    "deg_cosmo_path = OUT_FIGS / \"pipeline_degree_cosmo.png\"\n",
    "deg_quantum_path = OUT_FIGS / \"pipeline_degree_quantum.png\"\n",
    "\n",
    "plot_projection(combined, proj_path)\n",
    "plot_degree_hist(cosmo_graph, deg_cosmo_path)\n",
    "plot_degree_hist(quantum_graph, deg_quantum_path)\n",
    "\n",
    "proj_path, deg_cosmo_path, deg_quantum_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42f123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_path = OUT_PIPELINE / \"cleaned_combined.parquet\"\n",
    "features_path = OUT_PIPELINE / \"graph_features.parquet\"\n",
    "metrics_path = OUT_PIPELINE / \"baseline_metrics.json\"\n",
    "cosmo_graph_path = OUT_PIPELINE / \"cosmo_graph.gpickle\"\n",
    "quantum_graph_path = OUT_PIPELINE / \"quantum_graph.gpickle\"\n",
    "\n",
    "combined.to_parquet(clean_path, index=False)\n",
    "features_df.to_parquet(features_path, index=False)\n",
    "with metrics_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"accuracy\": baseline_metrics[\"accuracy\"], \"report\": baseline_metrics[\"report\"]}, f, indent=2)\n",
    "\n",
    "nx.write_gpickle(cosmo_graph, cosmo_graph_path)\n",
    "nx.write_gpickle(quantum_graph, quantum_graph_path)\n",
    "\n",
    "{\"data\": str(clean_path), \"features\": str(features_path), \"metrics\": str(metrics_path)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fa8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import requests\n",
    "\n",
    "    resp = requests.get(\"http://localhost:8000/ping\", timeout=2)\n",
    "    print(\"API /ping status\", resp.status_code, \"body\", resp.text[:200])\n",
    "except Exception as exc:  # noqa: BLE001\n",
    "    print(\"API check skipped or failed:\", exc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6d2632",
   "metadata": {},
   "source": [
    "### Что сохранили\n",
    "- Данные: `outputs/pipeline/cleaned_combined.parquet`\n",
    "- Графы: `outputs/pipeline/cosmo_graph.gpickle`, `outputs/pipeline/quantum_graph.gpickle`\n",
    "- Признаки: `outputs/pipeline/graph_features.parquet`\n",
    "- Метрики модели: `outputs/pipeline/baseline_metrics.json`\n",
    "- Визуализации: `reports/figures/pipeline_projection.png` и degree-hist для обоих графов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
